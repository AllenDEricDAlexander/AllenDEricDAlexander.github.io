

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/fluid.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
    <meta http-equiv="Content-Security-Policy" content="upgrade-insecure-requests">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="AtLuoFu">
  <meta name="keywords" content="二次元，宅属性，编程，全栈（后端-ing;前端-pass;网安-pass;运维-pass;产品-pass）">
  
    <meta name="description" content="欢迎你来读这篇博客，这篇博客主要是关于AI 论文收集。">
<meta property="og:type" content="article">
<meta property="og:title" content="AI 论文阅读">
<meta property="og:url" content="https://allendericdalexander.github.io/2024/04/03/paper/index.html">
<meta property="og:site_name" content="德刑君">
<meta property="og:description" content="欢迎你来读这篇博客，这篇博客主要是关于AI 论文收集。">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2024-04-03T12:00:00.000Z">
<meta property="article:modified_time" content="2024-04-03T12:00:00.000Z">
<meta property="article:author" content="AtLuoFu">
<meta property="article:tag" content="paper">
<meta property="article:tag" content="Deep Learning">
<meta name="twitter:card" content="summary_large_image">
  
  
    <meta name="referrer" content="no-referrer-when-downgrade">
  
  
  <title>AI 论文阅读 - 德刑君</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"allendericdalexander.github.io","root":"/","version":"1.9.7","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"LaTeX"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"follow_dnt":false,"baidu":{"enable":true,"id":"c76560edc451f0c6f297b2d80c3e5dcd"},"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  

  
    <!-- Baidu Analytics -->
    <script async>
      if (!Fluid.ctx.dnt) {
        var _hmt = _hmt || [];
        (function() {
          var hm = document.createElement("script");
          hm.src = "https://hm.baidu.com/hm.js?[object Object]";
          var s = document.getElementsByTagName("script")[0];
          s.parentNode.insertBefore(hm, s);
        })();
      }
    </script>
  

  
    <!-- Google tag (gtag.js) -->
    <script async>
      if (!Fluid.ctx.dnt) {
        Fluid.utils.createScript("https://www.googletagmanager.com/gtag/js?id=", function() {
          window.dataLayer = window.dataLayer || [];
          function gtag() {
            dataLayer.push(arguments);
          }
          gtag('js', new Date());
          gtag('config', '');
        });
      }
    </script>
  

  

  

  

  



  
<meta name="generator" content="Hexo 6.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>德刑君</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="AI 论文阅读"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2024-04-03 20:00" pubdate>
          2024年4月3日 晚上
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          8.5k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          72 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">AI 论文阅读</h1>
            
            
              <div class="markdown-body">
                
                <p>欢迎你来读这篇博客，这篇博客主要是关于<code>AI 论文收集</code>。</p>
<span id="more"></span>

<h3 id="序言"><a href="#序言" class="headerlink" title="序言"></a>序言</h3><p>在学习 Ai 的过程中，需要阅读大量的论文，我在此记录我所阅读过的关于 AI 的论文，如果您好更好的见解，欢迎到仓库的<a target="_blank" rel="noopener" href="https://github.com/AllenDEricDAlexander/AllenDEricDAlexander.github.io/issues">Issue</a><br>提交，我会进行合并处理（署名为你的 GitHub Name 和主页）。</p>
<h3 id="论文推荐"><a href="#论文推荐" class="headerlink" title="论文推荐"></a>论文推荐</h3><h3 id="DL"><a href="#DL" class="headerlink" title="DL"></a>DL</h3><h4 id="Deep-learning"><a href="#Deep-learning" class="headerlink" title="Deep learning"></a>Deep learning</h4><p>doi:10.1038&#x2F;nature14539</p>
<p>这篇论文价值极高，论文最后一章关于深度学习未来的探讨，和当今的发展高度吻合，作为学术考古和初学者来说，相信可以带来很大的启发。</p>
<p>摘要：深度学习允许由多个处理层组成的计算模型学习具有多个抽象级别的数据表示。这些方法极大地提高了语音识别、视觉对象识别、对象检测和许多其他领域（如药物发现和基因组学）的技术水平。深度学习通过使用反向传播算法来指示机器应该如何改变其内部参数，从而发现大型数据集中复杂的结构，这些参数用于从前一层的表示计算每一层的表达。深度卷积网络在处理图像、视频、语音和音频方面取得了突破，而递归网络则在文本和语音等序列数据方面大放异彩。</p>
<ul>
<li>引言<ul>
<li>机器学习技术在现代社会中发挥着重要作用，涵盖了从网络搜索到社交网络内容过滤，再到电子商务网站的推荐等多个方面，越来越多地应用于消费类产品如相机和智能手机中。</li>
<li>传统的机器学习技术在处理原始数据方面存在局限性，需要经过精心设计的特征提取器将原始数据转换为适当的内部表示或特征向量，以便进行模式识别或分类。</li>
<li>表征学习是一组方法，允许机器使用原始数据并自动发现用于检测或分类的表示。深度学习是具有多层表示的表征学习方法，通过组合简单但非线性的模块，将每个层次的表示转换为更高、稍微抽象的层次。</li>
<li>深度学习在解决长期困扰人工智能社区的问题方面取得了重大进展，特别擅长发现高维数据中的复杂结构，可应用于科学、商业和政府等多个领域。</li>
<li>深度学习在图像识别、语音识别、药物分子活性预测、粒子加速器数据分析、大脑回路重建等多个领域取得了突破性成果，并在自然语言理解方面表现出极大的潜力，尤其在主题分类、情感分析、问答和语言翻译等任务上表现出色。</li>
<li>预计深度学习在未来会取得更多成功，因为它几乎不需要手工工程，能够轻松利用计算和数据量的增加，并且当前正在开发的新学习算法和架构将加速这一进展。</li>
</ul>
</li>
<li>监督学习<ul>
<li>监督学习使得在 AI 训练的过程中，实现了自学习。</li>
<li>简要介绍了一下训练方法和迭代过程及效果。</li>
</ul>
</li>
<li>反向传播算法<ul>
<li>反向传播（backpropagation）是一种计算多层模块权重相对于目标函数梯度的实用方法，其核心思想是利用导数的链式法则。</li>
<li>反向传播过程中的梯度下降训练过程中的问题。</li>
</ul>
</li>
<li>卷积神经网络<ul>
<li>卷积神经网络背后的四个关键思想利用了自然信号的特性：局部连接、共享权重、池化和多层次使用。前几个阶段由两种类型的层组成：卷积层和池化层。</li>
<li>ConvNets 的成功得益于其对自然信号特性的深刻理解，并且通过构建层次化的特征表示来实现对复杂数据模态的高效处理和识别。</li>
</ul>
</li>
<li>基于深度卷积神经网络的图片理解<ul>
<li>介绍正则化在 DL 中的应用</li>
</ul>
</li>
<li>分布表示和语言模型<ul>
<li>学习分布式表示：这允许模型泛化到看不见的特征组合，从而获得更好的性能。层的组成：堆叠多层表示可以进行更强大的学习。</li>
<li>DL 模型学习捕获语义特征的词向量。这些特征不是预定义的，而是由网络在训练期间发现的。相似的单词具有相似的矢量表示，从而可以进行泛化。</li>
</ul>
</li>
<li>循环神经网络<ul>
<li>循环神经网络是一种特殊的人工神经网络，能够处理序列化的输入数据。RNN<br>在处理序列数据时，会将历史信息存储在一个叫做“状态向量”的隐藏单元中。通过反向传播算法，我们可以训练 RNN<br>模型，使其能够预测序列中的下一个元素</li>
<li>由于梯度爆炸和消失问题，早期 RNN 模型的训练难度较大。近年来，随着 RNN 架构和训练方法的改进，RNN 模型在各种序列处理任务上取得了显著成效。</li>
</ul>
</li>
<li>深度学习的未来<ul>
<li>从 91-98 年的无监督学习开始，深度学习重新引起了人们对人工智能的兴趣，但后来纯粹的监督学习取得了更大的成功，导致了对无监督学习的忽视。</li>
<li>虽然本文没有专门讨论无监督学习，但我们预计在长期内，无监督学习会变得更加重要。人类和动物的学习很大程度上是无监督的：我们通过观察世界来发现其结构，而不是被告知每个对象的名称。</li>
<li>人类视觉是一种主动过程，使用小型、高分辨率的中央凹区和大型、低分辨率的周围区域以智能、任务特定的方式顺序采样视觉阵列。<br>我们预计未来视觉领域的进展将来自于端到端训练的系统，将卷积神经网络与循环神经网络相结合，并使用强化学习来决定注视点的位置。</li>
<li>结合深度学习和强化学习的系统处于初期阶段，但它们已经在分类任务上胜过了被动视觉系统，并在学习玩许多不同视频游戏方面取得了令人印象深刻的成果。</li>
<li>自然语言理解是另一个深度学习即将在未来几年产生巨大影响的领域。我们期望使用循环神经网络理解句子或整个文档的系统，在学习逐步关注一部分内容的策略时会变得更加优秀。</li>
<li>最终，人工智能领域的重大进展将通过将表示学习与复杂推理相结合的系统实现。尽管深度学习和简单推理长期以来一直用于语音和手写识别，但需要新的范例来取代基于规则的符号表达式操作，而是使用大型向量的操作。</li>
</ul>
</li>
</ul>
<h3 id="CV"><a href="#CV" class="headerlink" title="CV"></a>CV</h3><h3 id="NLP"><a href="#NLP" class="headerlink" title="NLP"></a>NLP</h3><h4 id="Efficient-Estimation-of-Word-Representations-in-Vector-Space"><a href="#Efficient-Estimation-of-Word-Representations-in-Vector-Space" class="headerlink" title="Efficient Estimation of Word Representations in Vector Space"></a>Efficient Estimation of Word Representations in Vector Space</h4><p>arXiv.1301.3781v3</p>
<ul>
<li>author: google team</li>
</ul>
<p>总结：验证 word2vector 的重要性。</p>
<p>碎碎念：目前基本上做 NLP 的入门阶段必读此论文。对 NLP 领域的贡献是毋庸置疑的。</p>
<ul>
<li>Introduction<ul>
<li>介绍 word embedding 背景，本文目标，前人工作</li>
</ul>
</li>
<li>Model Architecture<ul>
<li>介绍前人工作</li>
<li>LSA&#x2F;LDA、前向神经网络、循环神经网络、并行神经网络；</li>
</ul>
</li>
<li>New Log-liner Models<ul>
<li>介绍 CBOW 和 Skip-grams</li>
</ul>
</li>
<li>Results<ul>
<li>评价任务描述;最大化正确率;模型结构比较;</li>
<li>模型上大量数据的并行计算;微软研究院句子完成比赛</li>
</ul>
</li>
<li>Examples of the LearnedRelationships<ul>
<li>例子:学习到的词与词之间的关系</li>
</ul>
</li>
<li>Conclusion<ul>
<li>高质量词向量;高效率训练方式;作为预训练词向量作用于其他 nlp 任务能提升效果</li>
</ul>
</li>
<li>Follow-Up Work<ul>
<li>后续工作:C++单机代码</li>
</ul>
</li>
</ul>
<h3 id="LLM"><a href="#LLM" class="headerlink" title="LLM"></a>LLM</h3><h4 id="ShortGPT-Layers-in-Large-Language-Models-are-More-Redundant-Than-You-Expect"><a href="#ShortGPT-Layers-in-Large-Language-Models-are-More-Redundant-Than-You-Expect" class="headerlink" title="ShortGPT: Layers in Large Language Models are More Redundant Than You Expect"></a>ShortGPT: Layers in Large Language Models are More Redundant Than You Expect</h4><p>arXiv.2403.03853v2</p>
<ul>
<li>author : 百川智能 - 中科院软件所</li>
</ul>
<p>总结：提出层去除和度量冗余层的方法，减少 25%的层将会导致模型性能大幅下降。效果看起来还是很不错的，还可以和量化结合。</p>
<p>碎碎念：不失是一个好方法，在 LLM 小型化的方向上，模型设计小型化、量化&amp;剪枝。属于剪枝创新。我感觉是挺索然无味的，质量不够啊，还得再加加。</p>
<ul>
<li>Introduction<ul>
<li>简单说了点 LLM 现状、量化、剪枝</li>
<li>工作内容：通过 BI 分析层冗余、删除冗余层剪枝</li>
</ul>
</li>
<li>Methodology<ul>
<li>层冗余：分析词嵌入矩阵。（想基于 retnet 开展吧可能）</li>
<li>层重要性：提出 BI 新指标</li>
<li>层去除</li>
</ul>
</li>
<li>Experiments<ul>
<li>模型选择：llama-2；benchmark &amp; baseline : 自己看论文吧</li>
<li>结果：有用</li>
</ul>
</li>
<li>Analysis<ul>
<li>剪枝比例的影响</li>
<li>深度冗余 与 宽度冗余</li>
<li>对非 TF 架构的 LLM 的效果探究</li>
<li>BI 标准</li>
</ul>
</li>
<li>Limitation<ul>
<li>层去除 25% 性能严重下滑。研究存在局限，需要更多的验证。</li>
</ul>
</li>
<li>Related works<ul>
<li>受前人工作启发：模型剪枝 &amp; 知识蒸馏 &amp; 量化 &amp; 低秩分解 &amp; 模型冗余</li>
</ul>
</li>
<li>Conclusion<ul>
<li>提出 BI 这种度量标准和层冗余、层去除的方法。对探索 DNN&amp;LLM 都有帮助。</li>
</ul>
</li>
</ul>
<h4 id="Leave-No-Context-Behind-Efficient-Infinite-Context-Transformers-with-Infini-attention"><a href="#Leave-No-Context-Behind-Efficient-Infinite-Context-Transformers-with-Infini-attention" class="headerlink" title="Leave No Context Behind: Efficient Infinite Context Transformers with Infini-attention"></a>Leave No Context Behind: Efficient Infinite Context Transformers with Infini-attention</h4><p>arXiv.2404.07143v1</p>
<ul>
<li>author : Google</li>
</ul>
<p>总结：提出一种 infini-attention 的架构，为 attention 家族添砖加瓦。类似 LLMs 内部的 RAGSys-思路清晰。</p>
<p>碎碎念：和 Ring-Attention 属于同一个课题。上下文限制的主要原因还是计算成本，一个是并行计算方向努力，一个是降低单机成本，提高单机效果。<br>有趣的是，做测试均测试的 1m 的 token，这个是 2404 发的。ring-attention 是 2310 发的，后续工作是 LWM 2402 发的（验证 1m token）。</p>
<ul>
<li>Introduction<ul>
<li>对与 transformers 及 LLMs 来说，长上下文的计算和内存成本很高。前人提出一种压缩记忆的方法。</li>
<li>基于此，提出 infini-attention。将旧的 KV 状态压缩存储，检索召回，聚合计算。效果&#x2F;实验结果描述-阿巴阿巴。</li>
</ul>
</li>
<li>Methods<ul>
<li>每层 attention 都有全局压缩状态和局部状态</li>
<li>与 multi-attention 方法类似、每层都是并行压缩。缩放点积注意力、压缩存储、检索、更新。几个关键步骤讲了一下。</li>
<li>支持无限上下文、详细说了一下压缩存储状态。</li>
</ul>
</li>
<li>Experiments<ul>
<li>长上下文建模、LLM 持续预训练</li>
</ul>
</li>
<li>Related works<ul>
<li>描述了一些前人工作和自己所受的启发。</li>
</ul>
</li>
<li>Conclusion<ul>
<li>记忆(压缩存储召回)对于长上下文、推理、计划和适应性都有价值。1m 的 token。</li>
</ul>
</li>
</ul>
<h4 id="Retentive-Network-A-Successor-to-Transformer-for-Large-Language-Models"><a href="#Retentive-Network-A-Successor-to-Transformer-for-Large-Language-Models" class="headerlink" title="Retentive Network: A Successor to Transformer for Large Language Models"></a>Retentive Network: A Successor to Transformer for Large Language Models</h4><p>arXiv.2307.08621v4</p>
<ul>
<li>author : Microsoft Research - Tsinghua University</li>
</ul>
<p>总结：算了，没看到模型怎么搞的。目前这个模型好像并没有爆炸性扩散。[2024-4]</p>
<p>碎碎念：[一年后重读]。</p>
<ul>
<li>Introduction<ul>
<li>TF 一家独大，但是 RetNet 有望实现“不可能三角”，介绍了三种前人工作，均不能实现不可能三角。</li>
<li>简要介绍 RetNet。测试结果还不错。</li>
</ul>
</li>
<li>Retentive Networks<ul>
<li>理论介绍与实现：看不懂。</li>
</ul>
</li>
<li>Experiments<ul>
<li>语言建模性能与 Zero&#x2F;few-shot 学习 &amp; 速度、内存消耗、延迟。</li>
<li>Setup | 与 tf 比较 | 训练消耗 | 推理消耗 | 与 tf 变体比较 | 消融实验</li>
</ul>
</li>
<li>Conclusion<ul>
<li>性能不错，可能会成为 tf 的理想继承者。</li>
</ul>
</li>
</ul>
<h4 id="Ring-Attention-with-Blockwise-Transformers-for-Near-Infinite-Context"><a href="#Ring-Attention-with-Blockwise-Transformers-for-Near-Infinite-Context" class="headerlink" title="Ring Attention with Blockwise Transformers for Near-Infinite Context"></a>Ring Attention with Blockwise Transformers for Near-Infinite Context</h4><p>arXiv.2310.01889v4</p>
<ul>
<li>author : 加州大学伯克利分校</li>
</ul>
<p>总结：文中提出了一种 Ring-Attention 的扩展上下文进行并行计算的新的 TF 内存高效计算架构。具有卓越的性能和上下文扩展能力。这种架构具有广阔的前景。</p>
<p>碎碎念：TF 架构并行计算领域的一大扩展。降低训练瓶颈，原本需要 A100，现在多搞点 4090 就行了。颇有三个臭皮匠，顶个诸葛亮的感觉。<br>这项工作已经被验证了对 LLMs （arXiv.2402.08268v2 - LWM 已经验证 同 UC Berkeley）具有卓越的影响。新的多模态大模型时代即将到来。而这，只是<br>AI 时代的序章。</p>
<p><a target="_blank" rel="noopener" href="https://docs.google.com/presentation/d/180lS8XbeR1_bTMaldg21LKYQkjXftHuh9VnZ3xk27qQ/edit#slide=id.p">相关演讲的 PPT</a></p>
<ul>
<li>Introduction<ul>
<li>tf 架构很成功，但是显存成本比较高。提出了 Ring-Attention 分布式训练。<ul>
<li>当我们逐块计算注意力时，结果对于这些块计算的顺序是不变的。我们的方法在主机之间分配计算块注意力的外循环，每个设备管理其各自的输入块。<br>对于内部循环，每个设备计算特定于其指定输入块的块式注意力和前馈操作。主机设备形成一个概念环，其中在内循环期间，每个设备将用于分块计算的键值块的副本发送到环中的下一个设备，同时从前一个设备接收键值块。<br>只要块计算比块传输花费更长的时间，与标准转换器相比，重叠这些过程就不会增加开销。但是有可以接受的通信开销。</li>
</ul>
</li>
<li>评估：Ring-Attention 是有价值的。此结构，理论上可以实现 无限制的 context size</li>
</ul>
</li>
<li>Large Context Memory Constraint<ul>
<li>论述了一下 tf 架构需要大量现存</li>
</ul>
</li>
<li>Ring Attention with Blockwise Parallel Transformers<ul>
<li>提出 Ring-Attention 并简要介绍一下。</li>
<li>分析了一下这样并行计算所需的开销。</li>
<li>贴出伪代码实现</li>
</ul>
</li>
<li>Setting<ul>
<li>benchmark setting：model、baselines、training configuration。介绍了一下。</li>
</ul>
</li>
<li>Results<ul>
<li>评估最大上下文：有个表、性能提升很多。</li>
<li>评估模型浮点计算率：有个表、可以训练很大的模型。</li>
<li>对上下文强化学习性能的影响：有个表、对于长序列和推理有优势。</li>
<li>对于 LLM 的影响：扩展 LLM 的上下文长度（arXiv.2402.08268v2 - LWM 已经验证 同 UC Berkeley）</li>
</ul>
</li>
<li>Related works<ul>
<li>这个工作属于 TF 高效内存计算类别。建议后续研究关于 attention 本身、更多的并行方法（数据并行、张量并行、序列并行、FSDP）</li>
<li>这个工作可以有效的提高并行计算能力并减少通信开销。（比较前人的一些工作）</li>
</ul>
</li>
<li>conclusion<ul>
<li>这个方法允许上下文随着设备数量线性扩展，并保持性能，消除单个设备带来的性能瓶颈。</li>
<li>通过大量训练证明了广阔的前景。</li>
</ul>
</li>
</ul>
<h4 id="LWM-WORLD-MODEL-ON-MILLION-LENGTH-VIDEO-ANDLANGUAGE-WITH-BLOCKWISE-RINGATTENTION"><a href="#LWM-WORLD-MODEL-ON-MILLION-LENGTH-VIDEO-ANDLANGUAGE-WITH-BLOCKWISE-RINGATTENTION" class="headerlink" title="LWM - WORLD MODEL ON MILLION-LENGTH VIDEO ANDLANGUAGE WITH BLOCKWISE RINGATTENTION"></a>LWM - WORLD MODEL ON MILLION-LENGTH VIDEO ANDLANGUAGE WITH BLOCKWISE RINGATTENTION</h4><p>arXiv.2402.08268v2</p>
<ul>
<li>author : 加州大学伯克利分校</li>
</ul>
<p>总结：这篇论文主要介绍了一种结合视频和语言的模型，通过使用 Blockwise RingAttention 和 Blockwise<br>Transformer 来训练长篇视频和书籍的数据集，并逐渐增加序列长度，从 32K 到 1M<br>tokens，以提高模型对复杂任务的理解能力。论文还介绍了一种构建 QA 数据集的方法，以便训练模型进行长序列对话。最后，论文展示了该模型在理解长视频和语言序列方面的出色表现。</p>
<p>碎碎念：个人认为 LWM 开启了一个新的训练方式（也可能是我孤陋寡闻，论文看少了）。这种训练方式方式带来的多模态大模型，从 32K 到 1M 的 token，渐进式训练方式，化是渐化，变是顿变。<br>变，言其著；化，言其渐。这种训练方式可能会帮助以后的 LLM 读取更长的 token，这种方式也比较合乎成长规律。文中也介绍了一些作者们训练时候的小技巧，提到了一种使用<br>Pallas 将<br>Blockwise Transformer 和 RingAttention 融合到一起的技巧，和他们的 QA 数据集。结合开源数据集有很好的效果。我强烈建议将 弱智吧<br>数据也加进去。<br>文中关于 Encoder 层做了较多的描述。但是对于 Decoder 层并没有做过多的描述。基于 TF 来说，如果能将 BERT(Encoder) 和 GPT(<br>Decoder) 这两种类型融合一下，</p>
<ul>
<li>Introduction<ul>
<li>介绍了一下这个领域当前的工作和挑战。</li>
<li>通过文本和长视频联合建模，提高模型对多模态和长文本的理解能力。</li>
<li>使用 blockwise ring-attention 技术降低计算成本，渐进式训练，混合训练，设计了一种屏蔽序列打包方式，多模态混合训练的平衡很重要，开发了一种 QA 训练方式。</li>
<li>贡献：context 转换器、长视频理解、平衡性问题、QA 数据集、开源。</li>
</ul>
</li>
<li>Overview<ul>
<li>基于 llama-2 训练了一个自回归 tf 模型，将 context 扩展到 1M，对多模态序列进行联合训练。</li>
</ul>
</li>
<li>阶段 1：训练 long-context 语言模型<ul>
<li>使用 Blockwise RingAttention 扩展上下文，并行将 Blockwise RingAttention 与 FlashAttention 融合。渐进训练。</li>
<li>分五个阶段，渐进训练。构建 QA 数据集，并微调，UltraChat 和论文自建的 QA 数据集，很好的配合训练。</li>
<li>评估：Multi-Needle Retrieval、基于上下文评估、聊天评估</li>
</ul>
</li>
<li>阶段 2：训练 long-context vision-language 模型<ul>
<li>基于阶段 1 输入 video 序列，进行训练。稍微修改了一下输入数据的架构。</li>
<li>用阶段 1 的模型进行训练，混合渐进式训练。</li>
<li>评估：长视频理解、图像理解、短视频理解、图像和视频生成</li>
</ul>
</li>
<li>更多细节<ul>
<li>描述了一下，训练所需资源，超参数</li>
</ul>
</li>
<li>相关工作<ul>
<li>工作涉及扩展语言模型的上下文窗口以允许更多 tokens。跟 CLIP 架构做了一下对比。</li>
</ul>
</li>
<li>结论<ul>
<li>效果很好，开创了一个需要资源少的、渐进式的训练方式，希望以后 token 可以更长、多模态能力更强。</li>
</ul>
</li>
</ul>
<h3 id="RAG"><a href="#RAG" class="headerlink" title="RAG"></a>RAG</h3><h4 id="Adaptive-RAG-Learning-to-Adapt-Retrieval-Augmented-Large-Language-Models-through-Question-Complexity"><a href="#Adaptive-RAG-Learning-to-Adapt-Retrieval-Augmented-Large-Language-Models-through-Question-Complexity" class="headerlink" title="Adaptive-RAG: Learning to Adapt Retrieval-Augmented Large Language Models through Question Complexity"></a>Adaptive-RAG: Learning to Adapt Retrieval-Augmented Large Language Models through Question Complexity</h4><p>arXiv.2403.14403v2</p>
<ul>
<li>author : 韩国高级科学技术研究院</li>
</ul>
<p>总结：提出了一种自适应增强检索模型，再次为 Prompt Engineering 加一分。</p>
<p>碎碎念：根据我的判断，这个项目是有价值的，后续我个人认为扩展方向可以往拓扑图及存储方向努力。<br>但是我已经提出了一种树形结构，来辅助检索召回，这份工作，我可以进行复现并进一步整合到我的工作中。<br>前段时间还有另外一篇论文论述了关于召回的不精确性问题，那个好像是二次召回。这两篇可以进一步整合到 RAGSys。</p>
<ul>
<li>Introduction<ul>
<li>大模型很强，但是也有很严重的幻觉问题。基于 RAG 的 LLM 在 QAsys 上有很大的作用。但是检索是较为复杂的过程。</li>
<li>提出了一个基于 pre-train LM 的选择&#x2F;分类器，预测所需的数据集。自适应选择数据包。增强效率和准确性。结果证明，很有用。</li>
</ul>
</li>
<li>Related works<ul>
<li>QA 系统很大的问题就是幻觉现象。RAG 一定程度上优化了这个情况。但是复杂问题需要多跳 RAG-QA，效率不高。前人也有一些思维链和自适应检索的工作。基于这些 work，</li>
<li>Adaptive-RAG 是预先确定复杂度并调整 LLM 的操作。</li>
</ul>
</li>
<li>Method<ul>
<li>介绍一下 QA-RAG-LLM 主要是多跳情况。</li>
<li>Adaptive-RAG：介绍一下和说明运行逻辑。</li>
</ul>
</li>
<li>实验<ul>
<li>数据集、模型、评估指标、实现细节</li>
<li>结果分析：Adaptive-RAG 表现出色。效果和效率都不错。<ul>
<li>分类器性能、分类器效率、分类器训练数据分析、分类器大小分析、案例研究</li>
</ul>
</li>
</ul>
</li>
<li>Conclusion<ul>
<li>设计目的是根据遇到的 查询的复杂性，在统一检索增强的 LLM 中动态调整其查询处理策略。</li>
<li>基于开放域 QA 数据集的集合，涵盖多种查询复杂性，包括单跳和多跳问题。</li>
<li>Adaptive-RAG 提高了 QA 系统的整体准确性和效率，分配更多的资源来处理复杂的查询，同时有效地处理更简单的查询。最大化的过度查询复杂性。</li>
</ul>
</li>
<li>Limitations<ul>
<li>自标记的模型可能会错误标记、分类器的可解释性问题、</li>
</ul>
</li>
<li>道德声明：阿巴阿巴</li>
<li>致谢：阿巴阿巴</li>
</ul>
<h4 id="RAG-鼻祖-Retrieval-Augmented-Generation-for-Knowledge-Intensive-NLP-Tasks"><a href="#RAG-鼻祖-Retrieval-Augmented-Generation-for-Knowledge-Intensive-NLP-Tasks" class="headerlink" title="RAG 鼻祖 - Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks"></a>RAG 鼻祖 - Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks</h4><p>arXiv.2005.11401v4</p>
<ul>
<li>author : 伦敦大学 - 纽约大学 - facebook AI 研究院</li>
</ul>
<p>总结：这篇论文介绍了检索增强生成（Retrieval-Augmented Generation，RAG）模型的研究。<br>这些模型结合了预训练的参数化记忆和非参数化记忆，用于语言生成任务。作者提出了两种 RAG 模型的形式，一种是在整个生成序列中条件于相同的检索到的段落，另一种是可以针对每个标记使用不同的段落。<br>他们在广泛的知识密集型自然语言处理任务上进行了微调和评估，并在三个开放领域问答任务上取得了最先进的结果，优于参数化的 seq2seq 模型和特定任务的检索和提取架构。<br>对于语言生成任务，研究发现 RAG 模型生成的语言比最先进的仅参数化的 seq2seq 基线更具体、更多样化和更符合事实。</p>
<p>个人一点小想法：RAG 从如今来看，无疑是带来了巨大反响。基于 RAG 的应用，层出不穷，后面又出现的 LangChain，我感觉扩展了 RAG 的定义，不再拘泥于文本任务，结合 Function<br>Call 和 Memory，LLM-Agent 等，<br>相信 Robot+Multi-RAGSys 将会重塑世界。</p>
<ul>
<li>Introduce<br>提出 Pre-train 神经语言模型的可以用，但是难以扩展，存在幻觉情况，通过参数记忆和非参数(检索)记忆可以检查并解释。提出了 RAG 模型，配图挺有意思的。效果还行。</li>
<li>Method<ul>
<li>提出两个模型，一个是基于 Sequence，一个是基于 Token。</li>
<li>检索使用 DPR。</li>
<li>生成使用 BERT。</li>
<li>训练方法简要介绍</li>
<li>解码的话，知识储备不够，看不懂</li>
</ul>
</li>
<li>Experiments<ul>
<li>开放 QA 场景</li>
<li>抽象 QA 场景</li>
<li>危险问题生成：评估真实性和特异性</li>
<li>事实审查：从 wiki 检索，然后对其进行推理审查。</li>
</ul>
</li>
<li>Results<ul>
<li>简述对以上测试场景进行测评的结果</li>
<li>RAG 之后，比原模型，完胜。</li>
</ul>
</li>
<li>Related Work<ul>
<li>单任务检索：功能更强大。</li>
<li>NLP 通用架构：增强原模型功能。</li>
<li>学习检索：获得更强大的性能。</li>
<li>基于存储架构：记忆。</li>
<li>检索和编辑方法：针对输出要求指定格式。RAG 未来可能有更好的应用。</li>
</ul>
</li>
<li>Discussion<ul>
<li>工作表明，RAG 更加真实、具体。可以热插拔检索功能。为 NLP 领域探究了一个新方向（现在来看，确实如此，甚至，不仅 NLP）</li>
<li>解决幻觉问题</li>
<li>缺点：容易受检索到的知识的影响，比如 wiki 或者 web 的内容有失偏颇。</li>
</ul>
</li>
</ul>
<h4 id="Social-Skill-Training-with-Large-Language-Models"><a href="#Social-Skill-Training-with-Large-Language-Models" class="headerlink" title="Social Skill Training with Large Language Models"></a>Social Skill Training with Large Language Models</h4><p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2404.04204.pdf">https://arxiv.org/pdf/2404.04204.pdf</a></p>
<ul>
<li>author : 斯坦福大学 - 佐治亚理工学院</li>
</ul>
<p>总结：这篇论文为社交恐惧症患者设计了一个交互应用，旨在帮助此类人群培养社交语言艺术，论文中提到了一个新模型 <strong>APAM</strong><br>，有两个不同性格的角色，帮助用户训练对话能力，设计了 2 + 3 种 Agent ，应对多种场景。文中也对 AI<br>带来的伦理道德问题进行了研究，对模型进行了测试。并针对一些问题，提出了解决方案，例如 LLM 幻觉问题，人文相关风险等。<br>最终对他们的工作进行了总结，对模型的未来发展进行了一定的论述，比如法律风险，对受众提供无风险实践机会等。</p>
<p>我个人感觉还是很有价值的，目前市场来说是有空缺的，提出的新模型也有一定的优势。但是感觉不够深入，还是基于 Prompt 工程进行 LLM 应用开发设计。</p>
<ul>
<li>简介<br>对当前现状进行了分析，目前是基于心理咨询师等进行沟通，提出如果基于大模型来说，成本将很低，风险也低。</li>
<li>用于性格植入和模拟的 LLMs<br>论述了很多相关技术如 RAG 和一些心理学上的理论。提出：模型是将重点 关注基于 LLM 的模拟，将其作为更灵活和可扩展的解决方案。提示的<br>LLM 可以有效地扮演可信的角色。</li>
<li>APAM framework<ul>
<li>AI partner：用户对话对象</li>
<li>AI monitor：扮演一个哲学家、心理学家的角色进行辅导用户</li>
<li>APAM 插图很形象，可以到论文里面看一看</li>
<li>方法论：了解用户，然后设计一个 partner 进行对话， 创建一个 monitor 导师进行辅助，将这两个 AI agent 植入到场景中，辅助用户开始训练。</li>
<li>示例：有个表，可以到论文里看看。</li>
</ul>
</li>
<li>Vision for Safe Deployment<ul>
<li>AI Partner Continuum： 提出了几个 partner 的设计。基于模拟学习的、基于角色扮演的、标准版。</li>
<li>AI Mentor Continuum：提出了几个 monitor 的设计。基于对话内容的、基于心理学理论体系的、结构化反馈的。</li>
</ul>
</li>
<li>Technical Challenge<ul>
<li>长对话优化：多轮对话不忘记问题、不幻想-基于对话互动、因人而异-因材施教。</li>
<li>集成专家框架：系统、有效、安全。基于 APAM，模型应该进行反思并优化自己。</li>
<li>基于用户控制的设计：允许用户微调。</li>
<li>个性化：基于用户情况进行针对性设计接下来的交互节奏。</li>
</ul>
</li>
<li>Evaluation<ul>
<li>完成以上挑战和愿景很有困难。进行了全自动评估和用户评估两种方式，参考指标例如困惑度或 Kullback-Leibler 散度。</li>
<li>开发人员进行了保证一致性等内容的 prompt 工程，解决评估问题，需要用户参与，不能单靠系统。</li>
<li>对于系统，存在一些风险，如 模拟失败、幻觉、过度依赖等问题，问题要详细暴露，不能汇总后传阅。（我猜，详细文本更有利于 fitting，毕竟 nlp 就这样）。</li>
</ul>
</li>
<li>讨论<ul>
<li>社会影响：很有用，帮助人学会换位思考等等。成本低，利好穷人。</li>
<li>担忧：法律风险和人文风俗风险。</li>
<li>Distributional Shifts：应该让用户意识到，他们对话的只是 AI，不是真人，现实中，应该随机应变。</li>
<li>Job Risks：APAM 不是为了代替人的工作，而是减轻心理咨询师的工作。针对偏远地区，进行普惠。</li>
</ul>
</li>
<li>总结<ul>
<li>阿巴阿巴。</li>
</ul>
</li>
</ul>
<h4 id="Chain-of-thought-prompting-elictis-reasoning-in-LLMs"><a href="#Chain-of-thought-prompting-elictis-reasoning-in-LLMs" class="headerlink" title="Chain of thought prompting elictis reasoning in LLMs"></a>Chain of thought prompting elictis reasoning in LLMs</h4><p>TODO 4-7</p>
<p>鸽子了、有空再说吧</p>
<h3 id="prompt-engineering"><a href="#prompt-engineering" class="headerlink" title="prompt engineering"></a>prompt engineering</h3><h4 id="LARGE-LANGUAGE-MODELS-ARE-HUMAN-LEVEL-PROMPT-ENGINEERS"><a href="#LARGE-LANGUAGE-MODELS-ARE-HUMAN-LEVEL-PROMPT-ENGINEERS" class="headerlink" title="LARGE LANGUAGE MODELS ARE HUMAN-LEVEL PROMPT ENGINEERS"></a>LARGE LANGUAGE MODELS ARE HUMAN-LEVEL PROMPT ENGINEERS</h4><p>arXiv.2211.01910v2 ICLR-2023</p>
<ul>
<li>author : 多伦多大学 - Vector Institute - 滑铁卢大学</li>
</ul>
<p>总结：这篇论文主要介绍了一种自动化生成指令的方法，称为 Automatic Prompt Engineer (APE)，通过搜索一组指令候选项来最大化所选的评分函数，从而选择最合适的指令。<br>实验结果表明，与人类生成的指令相比，利用 APE 生成的指令在各种任务上都能够取得更好的性能。论文提出，APE 可以帮助 LLM 在 few&#x2F;zero<br>shot 上取得更好的学习效果。</p>
<p>个人想法：算是为 prompt 工程领域添砖加瓦吧。AI 时代，终将大量 AI 替代这些繁琐的工作，且具备高效性和高质量。<br>工业革命本就是机器代替人，去标准化作业。电气时代，是电气设备的标准作业。信息时代是信息软件的标准作业。AI 时代，换成了 AI 进行标准作业。<br>目的均是追求生产统一的标准化产品。把误差控制在一定范围，越小越代表实力。不过，这个世界<strong>没有银弹</strong>，一切都要根据需求进行权衡。</p>
<ul>
<li>Introduction<ul>
<li>从 LLM 时代以来，一直在探索如何挖掘处 LLM 的指令。由于黑盒的特性，很难发掘出为什么看似相似的文本却让 LLM 的输出有较大的差异。为什么解决这个问题，设计了 APE 结构去进行探索。</li>
<li>使用 LLM 生成 prompt 指令，使用启发式搜索（迭代蒙特卡洛搜索方法）去筛选，作为黑盒优化。（关于可解释性问题，在其他论文中有提及，但是不多。）</li>
</ul>
</li>
<li>Related Work<ul>
<li>作者将 LLM 视作黑盒计算机，进行探索如何使用 LLM 生成指令来控制 LLM 行为。</li>
<li>简单介绍了一下 prompt engineering 和 程序实现，主要是叙述了一下前人的工作和自己的做法。</li>
</ul>
</li>
<li>具体工作<ul>
<li>prompt：首先 LLM 提出一些 prompt 文本。采用 前向生成 与 反向生成。通过反向生成模型，自定义补充提示。有一些插图，和一个代码流程伪代码，可以看看。</li>
<li>score：<ul>
<li>精度：采用的一个前人工作。</li>
<li>对数概率</li>
<li>分数评估：提出一种自适应过滤（高质量的接收多一点输入，低质量的少接受，类似 ResNet 概念的拓展）降低计算成本。</li>
</ul>
</li>
<li>迭代蒙特卡洛搜索方法：不懂</li>
</ul>
</li>
<li>LLM 是类人工程师<ul>
<li>从四个角度进行研究：零样本性能、少样本上下文学习性能、零样本思维链推理和真实性。我们的实验表明，APE<br>可以找到提高任务绩效的提示，其表现与人类编写的提示相同甚至更好。</li>
<li>任务效果：好。</li>
<li>大 bench：好。</li>
<li>零样本思维链：好。</li>
<li>问答的真实性：很高。</li>
</ul>
</li>
<li>定量分析<ul>
<li>增大模型，效果更好。</li>
<li>他们这个效果挺好，小模型多练练，效果也还行。评估指标也挺好。吹一下。</li>
<li>迭代蒙特卡洛搜索：迭代是有用的。</li>
</ul>
</li>
<li>总结：这项工作为控制和引导生成人工智能奠定了基础。<ul>
<li>笔者：确实，现在这方面做的还是不够好，虽然有 LangChain 这么方便的工具，但是 LangChain 没有引入 APE 进行自动生成<br>prompt。<code>2023-4-11</code></li>
</ul>
</li>
</ul>
<h3 id="Robot-Agent"><a href="#Robot-Agent" class="headerlink" title="Robot Agent"></a>Robot Agent</h3><h4 id="Learning-Agile-Soccer-Skills-for-a-Bipedal-Robot-with-Deep-Reinforcement-Learning"><a href="#Learning-Agile-Soccer-Skills-for-a-Bipedal-Robot-with-Deep-Reinforcement-Learning" class="headerlink" title="Learning Agile Soccer Skills for a Bipedal Robot with Deep Reinforcement Learning"></a>Learning Agile Soccer Skills for a Bipedal Robot with Deep Reinforcement Learning</h4><p>arXiv.2304.13653v1</p>
<ul>
<li>author : DeepMind - Google - University of Oxford</li>
</ul>
<p>总结：这项工作对未来大型机器人的具身智能训练指导了方向。对于后续小型机器人也可以进一步研究。对于未来的讨论很具有启发性。</p>
<p>碎碎念：什么时候研发色情服务机器人？</p>
<ul>
<li>Introduction<ul>
<li>介绍具身智能、介绍历史与前人工作</li>
<li>这项工作研究动态多智能体环境中小型人形机器人的全身控制和对象交互。结论：效果很好。Agent 的训练是通过重放和端到端训练和简单奖励实现的。证明了由虚拟仿真迁移到物理机器人也是可行的。</li>
</ul>
</li>
<li>Experimental Setup<ul>
<li>介绍用于训练代理的模拟和真实足球环境以及机器人硬件。</li>
</ul>
</li>
<li>Methods<ul>
<li>目标是训练一个智能体，将足球所需的各种技能（包括走、踢、起身、得分和防守）转化为长期战略行为，然后我们可以将其转移到真正的机器人上。</li>
<li>训练分两个阶段：1、针对某一技能特定训练（如走、踢球、防卫等）2、基于第一阶段学会了走进行战术和策略学习。对打越来越强的对手。考虑噪声情况以增强模型能力。</li>
<li>3.1 概述 - 看不懂。</li>
<li>3.2 训练 - 详细介绍了一下训练方式。</li>
<li>3.3 simulation to real world</li>
</ul>
</li>
<li>Results<ul>
<li>1v1 robot agent 表现了很优秀的能力（如：跌倒快速恢复、转身、移动踢球、战略行为等）</li>
<li>和 baseline 比较：1、定量分析（速度、跌倒起身能力、踢球 - DRL 效果很好）2、skill embedding</li>
<li>定位球：7&#x2F;10 - real</li>
<li>Value Function Analysis：研究了学习到的价值函数，以便直接验证代理对球、球门和对手的观察是否敏感</li>
<li>自我对弈：很重要。类似 GAN 的思想吧。</li>
</ul>
</li>
<li>Related works<ul>
<li>1、robot learning 2、Skill and Transfer Learning 3、Multi-agent Reinforcement Learning 4、RoboCup and Other<br>Competitive Games : 介绍了一下历史和现状</li>
</ul>
</li>
<li>Discussion<ul>
<li>局限：可以进一步均衡稳定性和活动。训练数据存在局限性，不利于用真实数据进行 pre-train。控制方法有待优化。仅用于小型机器人，大型机器人未考虑。</li>
<li>Comparison to RoboCup：灵感来自 RoboCup，未来工作的一个令人兴奋的方向是培训由两个或更多代理组成的团队。</li>
<li>Playing Soccer from Raw Vision：对环境的交互能力可以进一步提升。</li>
</ul>
</li>
<li>Conclusion<ul>
<li>sim to real 得到了令人惊讶的良好表现。本次实验了在小型机器人上的可行性，后续可以推广到大型机器人。</li>
</ul>
</li>
<li>Acknowledgements:阿巴阿巴</li>
</ul>
<h3 id="Software-Engineering"><a href="#Software-Engineering" class="headerlink" title="Software Engineering"></a>Software Engineering</h3><h4 id="AutoDev-Automated-AI-Driven-Development"><a href="#AutoDev-Automated-AI-Driven-Development" class="headerlink" title="AutoDev: Automated AI-Driven Development"></a>AutoDev: Automated AI-Driven Development</h4><p>arXiv.2403.08299v1</p>
<ul>
<li>author : Microsoft Redmond USA</li>
</ul>
<p>总结：吹牛逼居多。是一个方向，但是任务艰巨。目前的 AI 尚无此能力。看看 GPT-5 出来之后啥情况吧。如果 GPT-5 结合 Ring-Attention<br>大幅扩展上下文，还是有机会十年内的。</p>
<p>碎碎念：协作是一个不错的方向，但是精细化控制是做不到的。AI 没这种能力。后续持续优化此方向吧，厚积薄发，还是要看 Pre-train<br>Model 的能力。 2077 年或许可以完全 AI 化。</p>
<ul>
<li>Introduction<ul>
<li>现在的 AI 助手基本上还是 Copilot 这种类型。AutoDev 是全流程管理。基于 Auto Gen 的灵感，基于 Auto GPT。</li>
</ul>
</li>
<li>AutoDev Design<ul>
<li>Rules, Actions, and Objective Configuration ： Yaml 文件</li>
<li>Conversation Manager：人机交互，随机决策。<ul>
<li>Parser、Output Organizer、Conversation Conclusion、</li>
</ul>
</li>
<li>Agent Scheduler：编排 agent 协同工作。<ul>
<li>Agents：LLM &amp; SLM</li>
</ul>
</li>
<li>Tools Library：供 Function Call<ul>
<li>File Editing、Retrieval、Build &amp; Execution、Testing &amp; Validation、Git、Communication</li>
</ul>
</li>
<li>Evaluation Environment：Docker 中</li>
<li>Putting Everything Together：以上部分综合到一起，组合成 AutoDev</li>
</ul>
</li>
<li>Empirical Design<ul>
<li>Research Question：代码生成效果、测试任务生成效果、效率</li>
<li>AutoDev Settings：无人工干预效果怎么样</li>
</ul>
</li>
<li>Empirical Results<ul>
<li>代码生成任务：好；测试任务生成：还行；效率：还行；（大概率是测试集的问题导致还不错，目前 AI 并没有复杂工程能力[2024.4]）</li>
</ul>
</li>
<li>Discussion<ul>
<li>AutoDev in Action：有几张演示图</li>
<li>Multi-Agent Collaboration：协同效果会更好。联邦学习？</li>
<li>Human in the Loop：人机交互通过 ask 和 talk 进行传递指令，后续进行扩展。</li>
<li>AutoDev Integrations：未来希望集成到 IDE 中，目前还是命令行。</li>
</ul>
</li>
<li>Related Works<ul>
<li>AI in Software Engineering : 本文介绍了 AutoDev framework</li>
<li>Evaluation of LLMs in Software Engineering : 后续进行更复杂任务的训练</li>
<li>AI in Software Engineering Interactions : 总结了一下前人工作，可以看看。<ul>
<li>AutoDev 将这些想法专门用于软件工程领域，提供了一个灵活的框架，允许人工智能代理完全自主地完成复杂的 SE<br>任务。我们的工作旨在弥合传统软件工程实践和人工智能驱动的自动化之间的差距，促进开发人员和人工智能代理之间的协作。通过引入多功能工具库，AutoDev<br>使人工智能代理能够自主执行复杂的任务，从而在人工智能辅助软件开发领域取得了有希望的进步。</li>
</ul>
</li>
</ul>
</li>
<li>Conclusion : 阿巴阿巴</li>
</ul>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><h3 id="启示录"><a href="#启示录" class="headerlink" title="启示录"></a>启示录</h3><p><code>富贵岂由人，时会高志须酬。</code></p>
<p><code>能成功于千载者，必以近察远。</code></p>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/paper/" class="category-chain-item">paper</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/paper/" class="print-no-link">#paper</a>
      
        <a href="/tags/Deep-Learning/" class="print-no-link">#Deep Learning</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>AI 论文阅读</div>
      <div>https://allendericdalexander.github.io/2024/04/03/paper/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>AtLuoFu</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2024年4月3日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-by"></i>
                  </span>
                </a>
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">
                  <span class="hint--top hint--rounded" aria-label="NC - 非商业性使用">
                    <i class="iconfont icon-nc"></i>
                  </span>
                </a>
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">
                  <span class="hint--top hint--rounded" aria-label="SA - 相同方式共享">
                    <i class="iconfont icon-sa"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2024/04/06/system_analyst6/" title="系统分析师备考第六章-计算机网络">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">系统分析师备考第六章-计算机网络</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2024/04/01/yellow/" title="黄油">
                        <span class="hidden-mobile">黄油</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://allendericdalexander.github.io/" target="_blank" rel="nofollow noopener"><span>德刑君</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/AllenDEricDAlexander" target="_blank" rel="nofollow noopener"><span>GitHub</span></a> 
    </div>
  
  
    <div class="statistics">
  
  

  
    
      <span id="busuanzi_container_site_pv" style="display: none">
        总访问量 
        <span id="busuanzi_value_site_pv"></span>
         次
      </span>
    
    
      <span id="busuanzi_container_site_uv" style="display: none">
        总访客数 
        <span id="busuanzi_value_site_uv"></span>
         人
      </span>
    
    
  
</div>

  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>

  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
